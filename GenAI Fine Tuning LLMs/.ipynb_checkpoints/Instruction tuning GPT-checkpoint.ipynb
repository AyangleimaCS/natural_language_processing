{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5633ddc7-92cd-46c0-8d1c-c676ffc98104",
   "metadata": {},
   "source": [
    "#  Instruction-Tuning with LLMs\n",
    "\n",
    "\n",
    "Instruction-based fine-tuning, referred to as instruction GPT. It trains the language models to follow specific instructions and generate appropriate responses. For instruction-tuning, the dataset plays an important role as it provides structured examples of instructions, contexts, and responses, allowing the model to learn how to handle various tasks effectively. Instruction GPT often uses human feedback to refine and improve model performance; however, this lab doesn't cover this aspect.\n",
    "\n",
    "The context and instruction are concatenated to form a single input sequence that the model can understand and use to generate the correct response.\n",
    "\n",
    "#### Context and instruction\n",
    "\n",
    "\t•\tInstruction: A command to specify what the model should do\n",
    "\t•\tContext: Additional information or background required for performing the instruction\n",
    "\t•\tCombined input: The instruction and context combine together into a single input sequence\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e949f98a-a582-489c-9873-148942e3b87a",
   "metadata": {},
   "source": [
    "Let's review certain examples for various templates:\n",
    "\n",
    "---\n",
    "#### Response template\n",
    "Template: `### Question: {question}\\n ### Answer: {answer}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Question: What is the capital of France?\n",
    "### Answer: Paris\n",
    "```\n",
    "\n",
    "---\n",
    "#### Conversation template\n",
    "\n",
    "Template: `### User: {user_input}\\n ### Bot: {bot_response}`\n",
    "Example:\n",
    "```\n",
    "### User: How are you today?\n",
    "### Bot: I'm doing great, thank you! How can I assist you today?\n",
    "```\n",
    "\n",
    "---\n",
    "#### Instruction and output template\n",
    "\n",
    "Template: `### Instruction: {instruction}\\n ### Output: {output}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Instruction: Translate the following sentence to Spanish: \"Hello, how are you?\"\n",
    "### Output: \"Hola, ¿cómo estás?\"\n",
    "```\n",
    "\n",
    "---\n",
    "#### Completion template\n",
    "\n",
    "Template: `{prompt} ### Completion: {completion}`\n",
    "Example:\n",
    "```\n",
    "Once upon a time in a faraway land, ### Completion: there lived a wise old owl who knew all the secrets of the forest.\n",
    "```\n",
    "\n",
    "#### Summarization template\n",
    "\n",
    "Template: `### Text: {text}\\n ### Summary: {summary}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Text: The quick brown fox jumps over the lazy dog.\n",
    "### Summary: A fox jumps over a dog.\n",
    "```\n",
    "\n",
    "---\n",
    "#### Dialogue template\n",
    "\n",
    "Template: `### Speaker 1: {utterance_1}\\n ### Speaker 2: {utterance_2}\\n ### Speaker 1: {utterance_3}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Speaker 1: Hi, what are you doing today?\n",
    "### Speaker 2: I'm going to the park.\n",
    "### Speaker 1: That sounds fun!\n",
    "```\n",
    "\n",
    "---\n",
    "#### Code generation template\n",
    "\n",
    "Template: `### Task: {task_description}\\n ### Code: {code_output}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Task: Write a function to add two numbers in Python.\n",
    "### Code: def add(a, b):\\n    return a + b\n",
    "```\n",
    "\n",
    "---\n",
    "#### Data analysis template\n",
    "\n",
    "Template: `### Analysis Task: {task_description}\\n ### Analysis: {analysis_output}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Analysis Task: Provide insights from the sales data of Q1 2022.\n",
    "### Analysis: The sales increased by 15% compared to Q4 2021, with the highest growth in the electronics category.\n",
    "```\n",
    "\n",
    "---\n",
    "#### Recipe template\n",
    "\n",
    "Template: `### Recipe Name: {recipe_name}\\n ### Ingredients: {ingredients}\\n ### Instructions: {instructions}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Recipe Name: Chocolate Chip Cookies\n",
    "### Ingredients: Flour, Sugar, Chocolate Chips, Butter, Eggs, Vanilla Extract\n",
    "### Instructions: Mix the dry ingredients, add the wet ingredients, fold in the chocolate chips, and bake at 350°F for 10-12 minutes.\n",
    "```\n",
    "\n",
    "---\n",
    "#### Explanation template\n",
    "\n",
    "Template: `### Concept: {concept}\\n ### Explanation: {explanation}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Concept: Photosynthesis\n",
    "### Explanation: Photosynthesis is the process by which green plants use sunlight to synthesize nutrients from carbon dioxide and water.\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e0452-200a-43d6-97cf-b786ee278e60",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    " - Understand the various types of templates including instruction-response, question-answering, summarization, code generation, dialogue, data analysis, and explanation and their applications for fine-tuning large language models (LLMs).\n",
    " - Create and apply different templates to fine-tune LLMs for various tasks.\n",
    " - Format datasets based on the created templates to prepare them for effective model training\n",
    " - Perform instruction fine-tuning using Hugging Face libraries and tools\n",
    " - Apply Low-Rank Adaptation (LoRA) techniques to fine-tune LLMs efficiently\n",
    " - Configure and use the SFTTrainer for supervised fine-tuning of instruction-following models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061369e-ba57-4e1d-9375-04bee96d4c58",
   "metadata": {},
   "source": [
    "# __Table of contents__\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Install-required-libraries\">Install required libraries</a></li>\n",
    "            <li><a href=\"#Import-required-libraries\">Import required libraries</a></li>\n",
    "            <li><a href=\"#Define-the-device\">Define the device</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Dataset-description\">Dataset description</a></li>\n",
    "    <li><a href=\"#Model-and-tokenizer\">Model and tokenizer</a></li>\n",
    "    <li><a href=\"#Preprocessing-the-data\">Preprocessing the data</a></li>\n",
    "    <li><a href=\"#Test-the-base-model\">Test the base model</a></li>\n",
    "        <ol>\n",
    "            <li><a href=\"#BLEU-score\">BLEU score</a></li>\n",
    "        </ol>\n",
    "    <li><a href=\"#Perform-instruction-fine-tuning-with-LoRA\">Perform instruction fine-tuning with LoRA</a></li>\n",
    "    <li><a href=\"#Exercises\">Exercises</a></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c9f59aa-03c8-4e02-85a7-5d7ddfe3b824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 0.13.1 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n",
      "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.0 which is incompatible.\n",
      "torchvision 0.14.1 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --user -qq datasets==2.20.0 trl==0.9.6 transformers==4.42.3 peft==0.11.1 tqdm==4.66.4 numpy==1.26.4 pandas==2.2.2 matplotlib==3.9.1 seaborn==0.13.2 scikit-learn==1.5.1 sacrebleu==2.4.2 evaluate==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d92de06-2f37-4171-b0bf-9c99e0ed4de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages (0.4.2)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages (from evaluate) (2.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from evaluate) (0.29.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "  Attempting uninstall: evaluate\n",
      "    Found existing installation: evaluate 0.4.2\n",
      "    Uninstalling evaluate-0.4.2:\n",
      "      Successfully uninstalled evaluate-0.4.2\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0e7aa2-88dd-4e26-a8ce-79a60baab2a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"C:\\Users\\Lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages\\torch\\lib\\torch_python.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "File \u001b[1;32m~\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages\\torch\\__init__.py:262\u001b[0m\n\u001b[0;32m    258\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    260\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 262\u001b[0m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages\\torch\\__init__.py:258\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    254\u001b[0m             err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    255\u001b[0m             err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    256\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    257\u001b[0m             )\n\u001b[1;32m--> 258\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    260\u001b[0m kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\Lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages\\torch\\lib\\torch_python.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from urllib.request import urlopen\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e786426-cefc-42f9-9d27-e9c5af1acb57",
   "metadata": {},
   "source": [
    "### Define the device\n",
    "\n",
    "The below code will set your device to 'cuda' if your device is compatible with GPU, otherwise, you can use 'cpu'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077d284-0e70-4725-84aa-a7ea9feaa8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21d609-72bc-40f4-b35a-f553cb13e99b",
   "metadata": {},
   "source": [
    "# Dataset description\n",
    "\n",
    "Use the below sentences to download the CodeAlpaca 20k dataset, a programming code dataset. This code is available [here](https://github.com/sahil280114/codealpaca?tab=readme-ov-file#data-release). The CodeAlpaca dataset contains the following elements:\n",
    "\n",
    "\n",
    "- `instruction`: **str**, describes the task the model should perform. Each of the 20K instructions is unique.\n",
    "- `input`: **str**, optional context or input for the task. For example, when the instruction is \"Amend the following SQL query to select distinct elements\", the input is the SQL query. Around 40% of the examples have an input.\n",
    "- `output`: **str**, the answer to the instruction as generated by text-davinci-003.\n",
    "\n",
    "The following code block downloads the CodeAlpaca-20k dataset as a `json` file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "995f0e89-5e9c-4bdf-82b4-58615f530e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WzOT_CwDALWedTtXjwH7bA/CodeAlpaca-20k.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742b7b2-06b9-4fb0-8a2a-471ec4b6a5a4",
   "metadata": {},
   "source": [
    "Load the Dataset as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bb30529-7755-486a-9cd7-1299d418e173",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m, data_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCodeAlpaca-20k.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m dataset\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=\"CodeAlpaca-20k.json\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34efeee-3b66-49ed-ae71-8b08ff6dc996",
   "metadata": {},
   "source": [
    "Look at the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc68a8a-80d1-4ca2-a109-df4077bba38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff251b0-154a-4a7b-af7b-72a25ffb1cb0",
   "metadata": {},
   "source": [
    "To keep things simple let's just focus on the examples that do not have any `input`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c57df8-afe0-4dcb-96eb-3279d224eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(lambda example: example[\"input\"] == '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e77fd-b4bd-4fdf-926b-7670cc7dfb45",
   "metadata": {},
   "source": [
    "The original CodeAlpaca dataset may not have been shuffled. The following line indicates how to shuffle a `datasets.arrow_dataset.Dataset()` object with a random seed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275d1251-e3e2-4ab1-9e73-03511a858c01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8075344e-d16f-4b90-91b0-4cefac4f57f4",
   "metadata": {},
   "source": [
    "Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e60d7-cb41-479d-8898-6a41df488cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = dataset_split['train']\n",
    "test_dataset = dataset_split['test']\n",
    "dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830faef-b78e-46a4-abe5-fe54c92e050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a small set of data for the resource limitation\n",
    "# This dataset will be only used for evaluation parts, not for the training\n",
    "tiny_test_dataset=test_dataset.select(range(10))\n",
    "tiny_train_dataset=train_dataset.select(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db00de21-07cd-4e1f-82be-4d952091f8f6",
   "metadata": {},
   "source": [
    "# Model and tokenizer\n",
    "\n",
    "In this exercise, let's fine-tune the [`opt-350m`](https://huggingface.co/facebook/opt-350m) model from Facebook. A description of this OpenSource model was published [here](https://arxiv.org/abs/2205.01068), and the model was originally made available on [metaseq's Github repository](https://github.com/facebookresearch/metaseq).\n",
    "\n",
    "The below lines load the base model from Hugging Face:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132962b4-a7ce-4f3b-989b-5e09ef88858d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25303bc7-1165-4483-adab-adb76f3a123a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f0fc7-f68f-4e5a-8306-d421a6232a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e1cfe-6701-4636-a213-522e7b5e19e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec1671-ffab-47f4-b09d-c44b668a2fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b299c99e-7db9-446d-9227-870d6bad3bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad79b0-e9ff-4b8d-b17a-11e5c7ea8497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb5628-0f61-46a3-b3c3-4ec19c0e15ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
