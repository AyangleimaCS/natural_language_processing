{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644d785f-a59c-43b8-ae0f-6c8b5693fe01",
   "metadata": {},
   "source": [
    "Classifying Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28b4f7a-ab9f-45f1-8d47-7a9b1d69e4aa",
   "metadata": {},
   "source": [
    "The implementation of an automated machine learning system makes it very efficient. Such a system, equipped with advanced natural language processing and machine learning capabilities, could sift through the vast archives, categorizing articles into their respective topics with remarkable precision. As a result, readers would seamlessly access a wealth of knowledge tailored to their interests, while the editorial team gains newfound agility in content management.\n",
    "\n",
    "In this project, you will embark on the exciting task of classifying news articles for a content search engine. The goal is to build a model that can automatically categorize news articles into different topics or classes, enabling the search engine to deliver relevant content to users efficiently. To achieve this, you will leverage the powerful torchtext library, which simplifies the process of creating a dataset for text classification analysis.\n",
    "\n",
    "With torchtext, you'll have the flexibility to access and preprocess raw news data effortlessly. The library enables you to convert text strings into torch.Tensors, which are essential for training machine learning models. By using torchtext's convenient functionalities, you can set up an efficient data processing pipeline that prepares your text data for classification.\n",
    "\n",
    "Throughout this tutorial, you'll demonstrate how to effectively shuffle and iterate through the processed data using torch.utils.data.DataLoader. This DataLoader simplifies the data handling process, allowing you to focus on building and training your text classification model effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02660480-c59a-4b3a-b78d-4263b2841734",
   "metadata": {},
   "source": [
    "Table of Contents\n",
    "Objectives\n",
    "Setup\n",
    "Installing required libraries\n",
    "Importing required libraries\n",
    "Defining helper functions\n",
    "Text classification\n",
    "Import bank dataset\n",
    "Dataset\n",
    "Data loader\n",
    "Neural network\n",
    "Train The model\n",
    "Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcba7dd-60f9-4d70-b203-a5dae43920c5",
   "metadata": {},
   "source": [
    "OBJECTIVE:\n",
    "Work with datasets and understand tokenizer, embedding bag technique and vocabulary.\n",
    "Explore embeddings in PyTorch and understand token indices.\n",
    "Perform text classification using data loader and apply it on a neural network model.\n",
    "Train the text classification model on a news dataset.\n",
    "Engage in various exercises to solidify your understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dca03f7-7c5a-4441-b4c9-c528da255d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pmdarima in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (2.0.2)\n",
      "Collecting pmdarima\n",
      "  Using cached pmdarima-2.0.4-cp38-cp38-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima) (1.4.2)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.19 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima) (1.10.1)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima) (0.14.1)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima) (2.2.3)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima) (75.1.0)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pandas>=0.19->pmdarima) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pandas>=0.19->pmdarima) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pandas>=0.19->pmdarima) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from scikit-learn>=0.22->pmdarima) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from statsmodels>=0.13.2->pmdarima) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.19->pmdarima) (1.16.0)\n",
      "Using cached pmdarima-2.0.4-cp38-cp38-win_amd64.whl (615 kB)\n",
      "Installing collected packages: pmdarima\n",
      "  Attempting uninstall: pmdarima\n",
      "    Found existing installation: pmdarima 2.0.2\n",
      "    Uninstalling pmdarima-2.0.2:\n",
      "      Successfully uninstalled pmdarima-2.0.2\n",
      "Successfully installed pmdarima-2.0.4\n",
      "Collecting pmdarima==2.0.2\n",
      "  Using cached pmdarima-2.0.2-cp38-cp38-win_amd64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima==2.0.2) (1.4.2)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima==2.0.2) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima==2.0.2) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.19 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima==2.0.2) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima==2.0.2) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima==2.0.2) (1.10.1)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima==2.0.2) (0.14.1)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima==2.0.2) (2.2.3)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pmdarima==2.0.2) (75.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pandas>=0.19->pmdarima==2.0.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pandas>=0.19->pmdarima==2.0.2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from pandas>=0.19->pmdarima==2.0.2) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from scikit-learn>=0.22->pmdarima==2.0.2) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from statsmodels>=0.13.2->pmdarima==2.0.2) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from statsmodels>=0.13.2->pmdarima==2.0.2) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.19->pmdarima==2.0.2) (1.16.0)\n",
      "Using cached pmdarima-2.0.2-cp38-cp38-win_amd64.whl (571 kB)\n",
      "Installing collected packages: pmdarima\n",
      "  Attempting uninstall: pmdarima\n",
      "    Found existing installation: pmdarima 2.0.4\n",
      "    Uninstalling pmdarima-2.0.4:\n",
      "      Successfully uninstalled pmdarima-2.0.4\n",
      "Successfully installed pmdarima-2.0.2\n"
     ]
    }
   ],
   "source": [
    "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
    "!pip install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n",
    "# - Update a specific package\n",
    "!pip install pmdarima -U\n",
    "# - Update a package to specific version\n",
    "!pip install --upgrade pmdarima==2.0.2\n",
    "# Note: If your environment doesn't support \"!pip install\", use \"!mamba install\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2261d806-48e7-4896-a9a6-cb4a62ad9820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -U matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a5faed8-5724-444e-bad7-bb103c9fddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq portalocker>=2.0.0\n",
    "# !pip install -qq torchtext\n",
    "!pip install -qq torchdata\n",
    "!pip install -Uqq plotly\n",
    "!pip install -qq dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a483f9-c4ce-478b-8d65-7509a64eed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import accumulate\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import Markdown as md\n",
    "from torch.utils.data.dataset import random_split\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c5c106-2d5d-4d6f-8394-3de2c8232583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "# !pip install -qq torchtext\n",
    "# !pip install torchtext==0.15.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c68c72-2955-40a7-8589-56fdfaa0c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "441cab6c-af69-4d09-abf8-ae8214a8bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(COST,ACC):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(COST, color=color)\n",
    "    ax1.set_xlabel('epoch', color=color)\n",
    "    ax1.set_ylabel('total loss', color=color)\n",
    "    ax1.tick_params(axis='y', color=color)\n",
    "    \n",
    "    ax2 = ax1.twinx()  \n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('accuracy', color=color)  # you already handled the x-label with ax1\n",
    "    ax2.plot(ACC, color=color)\n",
    "    ax2.tick_params(axis='y', color=color)\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0bc107-757a-498a-8ced-956cee196c86",
   "metadata": {},
   "source": [
    "Text classification\n",
    "Let's build a text classification model using PyTorch and torchtext to classify news articles into one of the four categories: World, Sports, Business, and Sci/Tech."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26470417-2442-46f7-aca4-2675157fc722",
   "metadata": {},
   "source": [
    "Import bank dataset\n",
    "Load the AG_NEWS dataset for the train split and split it into input text and corresponding labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a3fd013-5b63-48d4-ac8f-df93f7850810",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter= iter(AG_NEWS(split=\"train\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0372894-dfcc-40ba-ab55-46c55445539f",
   "metadata": {},
   "source": [
    "\n",
    "The AG_NEWS dataset in torchtext does not support direct indexing like a list or tuple. It is not a random access dataset but rather an iterable dataset that needs to be used with an iterator. This approach is more effective for text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90bc2dc6-3c8b-46cc-a95b-dca93b9b3ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n"
     ]
    }
   ],
   "source": [
    "y,text= next((train_iter))\n",
    "print(y,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083bfcf8-f32d-48cb-815c-0ccbddb60aa3",
   "metadata": {},
   "source": [
    "Find the label of the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eacdd7d9-8d3c-41ff-9e73-70efcdb8d626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Business'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_news_label = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tec\"}\n",
    "ag_news_label[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f6e5f4-895b-4638-830f-c38bae73fd0b",
   "metadata": {},
   "source": [
    "Also, use the dataset to find all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccbdf673-00de-405f-8a0a-45ea418e7915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = len(set([label for (label, text) in train_iter ]))\n",
    "num_class "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778380d0-5076-41b8-a287-0d535a1b3563",
   "metadata": {},
   "source": [
    "Create tokens and also build the vocabulary as before, just using the AG dataset to obtain token indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5766ab2-03c1-494a-9561-466c24e933c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 95811\n",
      "Sample tokens: ['television', 'misnomer', 'television-watching', 'new', 'costs', '7-week', 'dutch', '35-10', 'tarceva', 'confidence']\n"
     ]
    }
   ],
   "source": [
    "# Reinitialize train_iter\n",
    "train_iter = AG_NEWS(split=\"train\")\n",
    "\n",
    "# Define tokenizer and yield_tokens\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text.lower())  # Lowercase conversion for consistency\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# Print the vocabulary size and sample tokens\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "print(f\"Sample tokens: {list(vocab.get_stoi().keys())[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d331d6a1-42a9-4b22-9054-d880bca7ec4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2120, 12544]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab([\"age\",\"hello\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b02eac-c9db-4e60-b937-5f314058ab2a",
   "metadata": {},
   "source": [
    "Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34db2f36-6e81-4756-ba2a-904cfdb0e2d1",
   "metadata": {},
   "source": [
    " The training dataset will contain 95% of the samples, while the validation dataset will contain the remaining 5%. These datasets can be used for training and evaluating a machine learning model for text classification on the AG_NEWS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d92bfda-f95d-4d3f-9186-b36532a88519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing iterators.\n",
    "train_iter, test_iter = AG_NEWS()\n",
    "\n",
    "# Convert the training and testing iterators to map-style datasets.\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "\n",
    "# Determine the number of samples to be used for training and validation (5% for validation).\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "\n",
    "# Randomly split the training dataset into training and validation datasets using `random_split`.\n",
    "# The training dataset will contain 95% of the samples, and the validation dataset will contain the remaining 5%.\n",
    "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21db5b11-677d-4849-9a24-475b7fa0bcc6",
   "metadata": {},
   "source": [
    "The code checks if a CUDA-compatible GPU is available in the system using PyTorch, a popular deep learning framework. If a GPU is available, it assigns the device variable to \"cuda\" (which stands for CUDA, the parallel computing platform and application programming interface model developed by NVIDIA). If a GPU is not available, it assigns the device variable to \"cpu\" (which means the code will run on the CPU instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02583bc8-693b-4c62-a5ab-326c6ac6a319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395ff325-a0e0-42e5-9d78-2e33fd2437fb",
   "metadata": {},
   "source": [
    "Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a9db81-de62-431b-99d7-240b5a6f05ea",
   "metadata": {},
   "source": [
    "Prepare the text processing pipeline with the tokenizer and vocabulary. The text and label pipelines will be used to process the raw data strings from the dataset iterators.\n",
    "\n",
    "The function text_pipeline will tokenize the input text, and vocab will then be applied to get the token indices. The label_pipeline will ensure that the labels start at zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "278c5811-878b-46b9-b3f4-3645b2214cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(x):\n",
    "  return vocab(tokenizer(x))\n",
    "\n",
    "def label_pipeline(x):\n",
    "   return int(x) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccfbe17-28b8-4a93-acc6-d8b572c53700",
   "metadata": {},
   "source": [
    "In PyTorch, the collate_fn function is used in conjunction with data loaders to customize the way batches are created from individual samples. The provided code defines a collate_batch function in PyTorch, which is used with data loaders to customize batch creation from individual samples. It processes a batch of data, including labels and text sequences. It applies the label_pipeline and text_pipeline functions to preprocess the labels and texts, respectively. The processed data is then converted into PyTorch tensors and returned as a tuple containing the label tensor, text tensor, and offsets tensor representing the starting positions of each text sequence in the combined tensor. The function also ensures that the returned tensors are moved to the specified device (e.g., GPU) for efficient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3e29963-257b-4133-8017-cef78400b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d9b82-757d-4dfa-a8d6-6a422e96eaf2",
   "metadata": {},
   "source": [
    "Convert the dataset objects to a data loader by applying the collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b0f77f7-0f21-411b-85d1-12e4d2db579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a027a-608c-4ebc-8546-bed33d490c99",
   "metadata": {},
   "source": [
    "You can observe the output sequence when you have the label, text, and offsets for each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5dffc40-7d77-4350-aabe-06d7882dc2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 1, 0, 0, 2, 1, 0, 3, 3, 0, 2, 3, 0, 0, 1, 3, 3, 3, 3, 2, 2, 2, 2, 2,\n",
       "         2, 0, 0, 3, 3, 2, 0, 0, 3, 2, 0, 2, 1, 3, 1, 3, 2, 1, 2, 2, 0, 1, 3, 2,\n",
       "         2, 1, 2, 3, 1, 1, 2, 0, 2, 2, 3, 1, 0, 2, 2, 0]),\n",
       " tensor([   2, 4361, 5137,  ...,    7,   70,    1]),\n",
       " tensor([   0,   47,   91,  141,  176,  209,  249,  298,  334,  352,  396,  446,\n",
       "          485,  524,  554,  607,  638,  669,  710,  742,  770,  808,  841,  878,\n",
       "          921,  961,  998, 1032, 1088, 1146, 1199, 1239, 1282, 1307, 1346, 1397,\n",
       "         1429, 1464, 1503, 1539, 1569, 1612, 1645, 1710, 1745, 1770, 1803, 1832,\n",
       "         1875, 1978, 2000, 2025, 2064, 2111, 2149, 2196, 2280, 2327, 2377, 2418,\n",
       "         2453, 2489, 2528, 2571]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label, text, offsets=next(iter(valid_dataloader ))\n",
    "label, text, offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2087f4a3-f76f-4a0e-bab9-c52f57fb41d4",
   "metadata": {},
   "source": [
    "Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa589a7f-f558-4bc7-8c60-6af90f02b9fb",
   "metadata": {},
   "source": [
    "\n",
    "You have created a neural network for a text classification model using an EmbeddingBag layer, followed by a softmax output layer. Additionally, you have initialized the model using a specific method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fe75251-449b-4758-bd74-064454f40c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7298ce28-2ccf-4f01-a9ac-7c994a5f8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "emsize=64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653429a-f287-43bb-a6e0-53a65e7a1417",
   "metadata": {},
   "source": [
    "You need the vocabulary size to determine the number of embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3953df8-cd03-4b8a-8954-7da0ceb5738b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95811"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9898e521-6bdd-4d43-aa7c-7484e1148c59",
   "metadata": {},
   "source": [
    "The number of classes for the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f71d787a-2e8b-4e69-907d-2cca8badbcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1902635-a27e-49c0-a09f-33f23e370ecb",
   "metadata": {},
   "source": [
    "Creating the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cee8220-3fc9-40d5-bcbc-99dd8fbdd51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (embedding): EmbeddingBag(95811, 64, mode='mean')\n",
       "  (fc): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c15ef-0ef9-4596-86e4-a108a2aedb6f",
   "metadata": {},
   "source": [
    "The code line predicted_label=model(text, offsets) is used to obtain predicted labels from a machine learning model for a given input text and its corresponding offsets. The model is the machine learning model being used for text classification or similar tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a0d58a5-569f-4ef8-8bb6-27d4770e94dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label=model(text, offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6746c974-af35-493f-9fcc-898204bc8cca",
   "metadata": {},
   "source": [
    "Now, verify the output shape of your model. In this case, the model is trained with a mini-batch size of 64 samples. The output layer of the model produces four logits for each neuron, corresponding to the four classes in the classification task. You can also create a function to find the accuracy given a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7ef2582-3c0b-4db0-91b1-032c8f74e970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fecdd2-4006-4241-abbb-c0e03f6f6e8a",
   "metadata": {},
   "source": [
    "Function predict takes in a text and a text pipeline, which preprocesses the text for machine learning. It uses a pre-trained model to predict the label of the text for text classification on the AG_NEWS dataset. The function returns the predicted label as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a14ce88-e607-42bf-893d-bc43027003dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return ag_news_label[output.argmax(1).item() + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb631430-eca8-4ee0-a521-4b09cdd00aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sports'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"I like sports\",text_pipeline )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe52db2-37be-4eb4-9d61-fc388ad28539",
   "metadata": {},
   "source": [
    "Create a function to evaluate the model's accuracy on a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "49f91fb9-b5ff-4ef5-a712-ca1a2e5ea969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count= 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f52432e-b729-4b6d-bce2-70cf57604054",
   "metadata": {},
   "source": [
    "The model was evaluated, and it was found that its performance is no better than average. This outcome is expected, considering that the model has not undergone any training yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c588e42-b52c-46ee-9979-509162733c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21355263157894736"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116d261f-b7ba-45c7-b962-7bfa1c8e74f9",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Set the learning rate (LR) to 0.1, which determines the step size at which the optimizer updates the model's parameters during training. The CrossEntropyLoss criterion is used to calculate the loss between the model's predicted outputs and the ground truth labels. This loss function is commonly employed for multi-class classification tasks.\n",
    "\n",
    "The chosen optimizer is Stochastic Gradient Descent (SGD), which optimizes the model's parameters based on the computed gradients with respect to the loss function. The SGD optimizer uses the specified learning rate to control the size of the weight updates.\n",
    "\n",
    "Additionally, a learning rate scheduler is defined using StepLR. This scheduler adjusts the learning rate during training, reducing it by a factor (gamma) of 0.1 after every epoch (step) to improve convergence and fine-tune the model's performance. These components together form the essential setup for training a neural network using the specified learning rate, loss criterion, optimizer, and learning rate scheduler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9cd9ffed-7273-4f33-9a1f-792fcd33f588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "199eaa53-60fe-4d73-916c-879409eaf13c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'maybe_upload_prof_stats_to_manifold' from 'torch._utils_internal' (C:\\Users\\Lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages\\torch\\_utils_internal.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m LR\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m----> 4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer, \u001b[38;5;241m1.0\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages\\torch\\optim\\sgd.py:27\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach, differentiable, fused)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSGD\u001b[39;00m(Optimizer):\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Implements stochastic gradient descent (optionally with momentum).\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    .. math::\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m       \\begin{aligned}\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m            &\\rule{110mm}{0.4pt}                                                                 \\\\\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m            &\\textbf{input}      : \\gamma \\text{ (lr)}, \\: \\theta_0 \\text{ (params)}, \\: f(\\theta)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m                \\text{ (objective)}, \\: \\lambda \\text{ (weight decay)},                          \\\\\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m            &\\hspace{13mm} \\:\\mu \\text{ (momentum)}, \\:\\tau \\text{ (dampening)},\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m            \\:\\textit{ nesterov,}\\:\\textit{ maximize}                                     \\\\[-1.ex]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m            &\\rule{110mm}{0.4pt}                                                                 \\\\\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m            &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m            &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m            &\\hspace{5mm}\\textbf{if} \\: \\lambda \\neq 0                                           \\\\\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m            &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m            &\\hspace{5mm}\\textbf{if} \\: \\mu \\neq 0                                               \\\\\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m            &\\hspace{10mm}\\textbf{if} \\: t > 1                                                   \\\\\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m            &\\hspace{15mm} \\textbf{b}_t \\leftarrow \\mu \\textbf{b}_{t-1} + (1-\\tau) g_t           \\\\\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m            &\\hspace{10mm}\\textbf{else}                                                          \\\\\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;124;03m            &\\hspace{15mm} \\textbf{b}_t \\leftarrow g_t                                           \\\\\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m            &\\hspace{10mm}\\textbf{if} \\: \\textit{nesterov}                                       \\\\\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m            &\\hspace{15mm} g_t \\leftarrow g_{t} + \\mu \\textbf{b}_t                             \\\\\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m            &\\hspace{10mm}\\textbf{else}                                                   \\\\[-1.ex]\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m            &\\hspace{15mm} g_t  \\leftarrow  \\textbf{b}_t                                         \\\\\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m            &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}                                          \\\\\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m            &\\hspace{10mm}\\theta_t \\leftarrow \\theta_{t-1} + \\gamma g_t                   \\\\[-1.ex]\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m            &\\hspace{5mm}\\textbf{else}                                                    \\\\[-1.ex]\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m            &\\hspace{10mm}\\theta_t \\leftarrow \\theta_{t-1} - \\gamma g_t                   \\\\[-1.ex]\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m            &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m            &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m            &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m       \\end{aligned}\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    Nesterov momentum is based on the formula from\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    `On the importance of initialization and momentum in deep learning`__.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m        params (iterable): iterable of parameters to optimize or dicts defining\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m            parameter groups\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m        lr (float): learning rate\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m        momentum (float, optional): momentum factor (default: 0)\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m        dampening (float, optional): dampening for momentum (default: 0)\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m        nesterov (bool, optional): enables Nesterov momentum (default: False)\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m        maximize (bool, optional): maximize the params based on the objective, instead of\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m            minimizing (default: False)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m        foreach (bool, optional): whether foreach implementation of optimizer\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m            is used (default: None)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m        >>> # xdoctest: +SKIP\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m        >>> optimizer.zero_grad()\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m        >>> loss_fn(model(input), target).backward()\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m        >>> optimizer.step()\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    __ http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m        The implementation of SGD with Momentum/Nesterov subtly differs from\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m        Sutskever et. al. and implementations in some other frameworks.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m        Considering the specific case of Momentum, the update can be written as\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m        .. math::\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m            \\begin{aligned}\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m                v_{t+1} & = \\mu * v_{t} + g_{t+1}, \\\\\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m                p_{t+1} & = p_{t} - \\text{lr} * v_{t+1},\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m            \\end{aligned}\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m        where :math:`p`, :math:`g`, :math:`v` and :math:`\\mu` denote the\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m        parameters, gradient, velocity, and momentum respectively.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m        This is in contrast to Sutskever et. al. and\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m        other frameworks which employ an update of the form\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m        .. math::\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m            \\begin{aligned}\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m                v_{t+1} & = \\mu * v_{t} + \\text{lr} * g_{t+1}, \\\\\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m                p_{t+1} & = p_{t} - v_{t+1}.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m            \\end{aligned}\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m        The Nesterov version is analogously modified.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, params, lr\u001b[38;5;241m=\u001b[39mrequired, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dampening\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     94\u001b[0m                  weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, foreach: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     95\u001b[0m                  differentiable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m required \u001b[38;5;129;01mand\u001b[39;00m lr \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages\\torch\\optim\\optimizer.py:284\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m foreach:\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, per_dtype_grads \u001b[38;5;129;01min\u001b[39;00m per_device_and_dtype_grads\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 284\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m grads \u001b[38;5;129;01min\u001b[39;00m per_dtype_grads\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m    285\u001b[0m             torch\u001b[38;5;241m.\u001b[39m_foreach_zero_(grads)\n",
      "File \u001b[1;32m~\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages\\torch\\_compile.py:22\u001b[0m, in \u001b[0;36minner\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages\\torch\\_dynamo\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[1;32m~\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Dict, List, Optional, Set\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m maybe_upload_prof_stats_to_manifold\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lazy_graph_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     _use_lazy_graph_module,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traceback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CapturedTraceback\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'maybe_upload_prof_stats_to_manifold' from 'torch._utils_internal' (C:\\Users\\Lenovo\\anaconda2024\\envs\\ml_env_v1\\lib\\site-packages\\torch\\_utils_internal.py)"
     ]
    }
   ],
   "source": [
    "LR=0.1\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7901333-4438-4251-8665-bf35e2b644de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "0.18.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "print(torch.__version__)\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351312a-270b-4b96-94a8-ddb5ca563ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "cum_loss_list=[]\n",
    "acc_epoch=[]\n",
    "acc_old=0\n",
    "\n",
    "for epoch in tqdm(range(1, EPOCHS + 1)):\n",
    "    model.train()\n",
    "    cum_loss=0\n",
    "    for idx, (label, text, offsets) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        cum_loss+=loss.item()\n",
    "\n",
    "    cum_loss_list.append(cum_loss)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    acc_epoch.append(accu_val)\n",
    "\n",
    "    if accu_val > acc_old:\n",
    "      acc_old= accu_val\n",
    "      torch.save(model.state_dict(), 'my_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e64ddb-a12c-46c0-9219-5df079694df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(cum_loss_list,acc_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a4bcf-0226-48b1-8ab7-ce8ce6d747ce",
   "metadata": {},
   "source": [
    "You can evaluate the results on the test data and achieve over 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10f05b-c25f-4155-8983-9a05fb48db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f35223-98c5-47b0-8bca-bd8d42143864",
   "metadata": {},
   "source": [
    "This code snippet provides a summary for generating a 3D t-SNE visualization of embeddings using Plotly. It demonstrates how words that are similar to each other are positioned closer together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019b2b1-2579-4f3b-a84d-ede2071afb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first batch from the validation data\n",
    "batch = next(iter(valid_dataloader))\n",
    "\n",
    "# Extract the text and offsets from the batch\n",
    "label, text, offsets = batch\n",
    "\n",
    "# Send the data to the device (GPU if available)\n",
    "text = text.to(device)\n",
    "offsets = offsets.to(device)\n",
    "\n",
    "# Get the embeddings bag output for the batch\n",
    "embedded = model.embedding(text, offsets)\n",
    "\n",
    "# Convert the embeddings tensor to a numpy array\n",
    "embeddings_numpy = embedded.detach().cpu().numpy()\n",
    "\n",
    "# Perform t-SNE on the embeddings to reduce their dimensionality to 3D.\n",
    "X_embedded_3d = TSNE(n_components=3).fit_transform(embeddings_numpy)\n",
    "\n",
    "# Create a 3D scatter plot using Plotly\n",
    "trace = go.Scatter3d(\n",
    "    x=X_embedded_3d[:, 0],\n",
    "    y=X_embedded_3d[:, 1],\n",
    "    z=X_embedded_3d[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=label.numpy(),  # Use label information for color\n",
    "        colorscale='Viridis',  # Choose a colorscale\n",
    "        opacity=0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "layout = go.Layout(title=\"3D t-SNE Visualization of Embeddings\",\n",
    "                   scene=dict(xaxis_title='Dimension 1',\n",
    "                              yaxis_title='Dimension 2',\n",
    "                              zaxis_title='Dimension 3'))\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de74ab-aa9f-425c-9c1b-0842e9087164",
   "metadata": {},
   "source": [
    "PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "84d744a5-0047-47a8-b609-d2ccef84d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "article=\"\"\"Canada navigated a stiff test against the Republic of Ireland on a rain soaked evening in Perth, coming from behind to claim a vital 2-1 victory at the Womens World Cup.\n",
    "Katie McCabe opened the scoring with an incredible Olimpico goal  scoring straight from a corner kick  as her corner flew straight over the despairing Canada goalkeeper Kailen Sheridan at Perth Rectangular Stadium in Australia.\n",
    "Just when Ireland thought it had safely navigated itself to half time with a lead, Megan Connolly failed to get a clean connection on a clearance with the resulting contact squirming into her own net to level the score.\n",
    "Minutes into the second half, Adriana Leon completed the turnaround for the Olympic champion, slotting home from the edge of the area to seal the three points.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f57d88-c929-4c3f-8028-f576abd14521",
   "metadata": {},
   "source": [
    "This markdown content generates a styled box with light gray background and padding. It contains an `<h3>` header displaying the content of the `article` variable, and an `<h4>` header indicating the predicted category of the news article which is provided by the `result` variable. The placeholders `{article}` and `{result}` will be dynamically replaced with actual values when this markdown is rendered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f78def-43fc-44c1-b2fe-b0087de275c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(article, text_pipeline)\n",
    "\n",
    "markdown_content = f'''\n",
    "<div style=\"background-color: lightgray; padding: 10px;\">\n",
    "    <h3>{article}</h3>\n",
    "    <h4>The category of the news article: {result}</h4>\n",
    "</div>\n",
    "'''\n",
    "\n",
    "md(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110cc9f0-8ac8-43b8-b93c-b94eb9813c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e74f1-0cc6-4ea6-b9c2-f674379de720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
